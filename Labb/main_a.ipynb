{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearRegression.py\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "class LinearRegression: \n",
    "    def __init__(self, X, features, Y, response):\n",
    "        self._X = X \n",
    "        self.Y = Y \n",
    "        self.features = features\n",
    "        self.response = response  \n",
    " \n",
    "    @property \n",
    "    def X(self):\n",
    "        X = self._X\n",
    "        X = np.column_stack([np.ones(X.shape[0]), X])\n",
    "        return X\n",
    "    \n",
    "    @property\n",
    "    def n(self):\n",
    "        return self._X.shape[0]\n",
    "    \n",
    "    @property\n",
    "    def d(self):\n",
    "        return self._X.shape[1] \n",
    "     \n",
    "    @property \n",
    "    def b(self):\n",
    "        X = self.X \n",
    "        Y = self.Y\n",
    "        return np.linalg.pinv( X.T @ X) @ X.T @ Y\n",
    "        \n",
    "    # SSE | Residual Sum of Squares | Sum of Squared Error\n",
    "    # The closer this is to zero the more accuret the prediction (in theory)\n",
    "    @property \n",
    "    def SSE(self):\n",
    "        X, Y, b = self.X, self.Y, self.b\n",
    "        return  sum( np.square( Y - X @ b ) )\n",
    "    \n",
    "    # SSR | Explained Sum of Squares | Regression Sum of Squares\n",
    "    @property\n",
    "    def SSR(self):\n",
    "        X, Y_mean, b = self.X, self.Y.mean(), self.b\n",
    "        return sum( np.square( X @ b - Y_mean ) )\n",
    "    \n",
    "    # SST | Syy | Total Sum of Squares\n",
    "    @property \n",
    "    def SST(self):\n",
    "        Y = self.Y\n",
    "        Y_mean = Y.mean() \n",
    "        return sum( np.square(Y-Y_mean) )\n",
    "    \n",
    "    # Picks the confidence level\n",
    "    # If it's below 0.68 it sets it to R2 \n",
    "    @property \n",
    "    def confidence_level(self):\n",
    "        R2 = self.R2()  \n",
    "        confidence_levels = [0.997, 0.95, 0.9, 0.8, 0.68, R2]\n",
    "        return [ cl for cl in confidence_levels if cl <= R2 ][0]\n",
    "\n",
    "    def print_all(self):\n",
    "        all = f\"\"\"\n",
    "G\n",
    "1.    Features: {self.d}\n",
    "2. Sample Size: {self.n}\n",
    "3.    Variance: {self.var()}\n",
    "4. S.Diviation: {self.std()}\n",
    "5. Significance: {self.sig()}\n",
    "6.   Relevance: {self.R2()}\n",
    "\n",
    "VG\n",
    "1. Individual Significance\n",
    "{ str().join( f\"{row}\\n{str()}\" for row in self.sig_var().split(\"\\n\") ) }2. Pairs of Pearsons\n",
    "{ str().join( f\"{row}\\n{str()}\" for row in self.pearson().split(\"\\n\") ) }3. Confidence Interval \n",
    "{ str().join( f\"{row}\\n{str()}\" for row in self.con_int().split(\"\\n\") ) }4. Confidence Level: {self.confidence_level}\n",
    "         \"\"\"\n",
    "        print(all)\n",
    "\n",
    "    # The Method that Calculates The Variance | S^ | sigma^2 \n",
    "    # On average how far our actual responses are from the regression line\n",
    "    def var(self):\n",
    "        SSE, n, d = self.SSE, self.n, self.d \n",
    "        return SSE/(n - d - 1)\n",
    "\n",
    "    \n",
    "    # The Method that Calculated The Standard Deviation | S | sigma\n",
    "    # Meassure the same thing as the Variances but in a more readable but less fair unit\n",
    "    def std(self):\n",
    "        var = self.var()\n",
    "        return np.sqrt(var)\n",
    "    \n",
    "    # The Method that reports The Significance of the Regression\n",
    "    # The closer the pvalue is to zero the more \n",
    "    # confidently we can reject the null-hypothesis (H0)\n",
    "    # If the null-hypothesis is true then it means that \n",
    "    # there is no relationship between the features and the response\n",
    "    # In order to reject the H0-hypothesis we want the p-value of at least 0.05 aka 5%\n",
    "    # this would mean that there is a 95% chances that our features have an effect on the response\n",
    "    def sig(self): \n",
    "        SSR, d, n, var = self.SSR, self.d, self.n, self.var()\n",
    "        \n",
    "        sig_statistic = (SSR/d)/var\n",
    "     \n",
    "        # Survival Function of the F-Distrubution\n",
    "        p_significance = stats.f.sf(sig_statistic, d, n-d-1)\n",
    "        return p_significance\n",
    "    \n",
    "    \n",
    "    # The method that reports The Relevance of Regression\n",
    "    # Reports how big percent of the calculated responses that falls within \n",
    "    # our normal distribution aka how big of a range of responses that our model can \n",
    "    # reliably predict. So if our R2 value is 0.90 than we could predict 90% of \n",
    "    # all responses within or relatively close to the marign of error\n",
    "    def R2(self):\n",
    "        SSR, SST = self.SSR, self.SST\n",
    "        return SSR/SST\n",
    "\n",
    "\n",
    "    # Significance of the Variables\n",
    "    def sig_var(self):   \n",
    "        X, b, d, n, std, var, features = self.X, self.b, self.d, self.n, self.std(), self.var(), self.features\n",
    "    \n",
    "        # Variance/Covariance Matrix\n",
    "        c = np.linalg.pinv( (X.T @ X) )*var\n",
    "\n",
    "        # Significans Statisitca Array\n",
    "        ssa = [ b[i]/(std * np.sqrt(c[i,i])) for i in range(1, c.shape[1])]\n",
    "        \n",
    "        cdf = stats.t.cdf(ssa, n-d-1)\n",
    "        sf =  stats.t.sf(ssa, n-d-1)\n",
    "        p = [ 2 * min(cdf[idx], sf[idx]) for idx in range(len(ssa)) ]\n",
    "\n",
    "        result = str().join( f\"{features[idx]:<10}: pvalue = {p[idx]}\\n\" for idx in range(len(p))  )\n",
    "        return result\n",
    "\n",
    "    # The Method that calculates the Pearson number between all pairs of parameters\n",
    "    def pearson(self):\n",
    "        X, features = self.X, self.features\n",
    "        \n",
    "        result = list()\n",
    "        \n",
    "    \n",
    "        X = X[:,1:]\n",
    "        for idx in range(len(features)):\n",
    "            for idy in range(idx):\n",
    "                if idy == idx:\n",
    "                    continue \n",
    "                p = stats.pearsonr(X.T[idx], X.T[idy])    \n",
    "                result.append(f\"{features[idx]} VS {features[idy]:<10} : {p[0]:<20}\\n\")\n",
    "        \n",
    "        return str().join(result[::-1])\n",
    "        \n",
    "    \n",
    "    # The method that calculates the Confidence Interval\n",
    "    def con_int(self):\n",
    "        X,  b, n, d, var, std, features = self.X, self.b, self.n, self.d, self.var(), self.std(), self.features\n",
    "      \n",
    "\n",
    "         \n",
    "        c = np.linalg.pinv( (X.T @ X) )*var\n",
    "        a = 1-self.confidence_level \n",
    "        df = n-d-1\n",
    "        results = list()\n",
    "\n",
    "        for i in range(1,d+1):           \n",
    "            ci = (b[i], stats.t.ppf(a/2, df) * std * np.sqrt(c[i][i]))\n",
    "            #result = f\"{features[i-1]}: {ci[0]:.5f} ± {abs(ci[1]):.5f} | interval:[{(ci[0]-ci[1]):.5f}, {(ci[0]+ci[1]):.5f}]\\n\"\n",
    "            result = f\"{features[i-1]}: {ci[0]:.5f} ±\"\n",
    "            results.append(result)\n",
    "        \n",
    "        return str().join(results)   \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"../Resources/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to numpy.ndarray.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[155], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m flow \u001b[38;5;241m=\u001b[39m LinearRegression(X\u001b[38;5;241m.\u001b[39mvalues,\u001b[38;5;28mlist\u001b[39m(X\u001b[38;5;241m.\u001b[39mcolumns),Y\u001b[38;5;241m.\u001b[39mvalues,Y\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#print( flow.con_int() )\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#flow.SSR\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#import scipy.stats as st\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#scipy.stats.norm.ppf(0.975, 1, 0)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#flow.con_int()\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#flow.print_all()\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[153], line 74\u001b[0m, in \u001b[0;36mLinearRegression.print_all\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_all\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;28mall\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124mG\u001b[39m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;124m1.    Features: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124m2. Sample Size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124m3.    Variance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar()\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124m4. S.Diviation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124m5. Significance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msig()\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124m6.   Relevance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR2()\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[38;5;124mVG\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124m1. Individual Significance\u001b[39m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mstr\u001b[39m()\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;250m \u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mrow\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msig_var()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;250m \u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m2. Pairs of Pearsons\u001b[39m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mstr\u001b[39m()\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;250m \u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mrow\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpearson()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;250m \u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m3. Confidence Interval \u001b[39m\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mstr\u001b[39m()\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;250m \u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mrow\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;250m \u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m4. Confidence Level: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfidence_level\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124m         \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mall\u001b[39m)\n",
      "Cell \u001b[1;32mIn[153], line 167\u001b[0m, in \u001b[0;36mLinearRegression.con_int\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m     ci \u001b[38;5;241m=\u001b[39m (b[i], stats\u001b[38;5;241m.\u001b[39mt\u001b[38;5;241m.\u001b[39mppf(a\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, df) \u001b[38;5;241m*\u001b[39m std \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(c[i][i]))\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m#result = f\"{features[i-1]}: {ci[0]:.5f} ± {abs(ci[1]):.5f} | interval:[{(ci[0]-ci[1]):.5f}, {(ci[0]+ci[1]):.5f}]\\n\"\u001b[39;00m\n\u001b[1;32m--> 167\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeatures[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mci\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m.5f\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124m ±\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m()\u001b[38;5;241m.\u001b[39mjoin(results)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported format string passed to numpy.ndarray.__format__"
     ]
    }
   ],
   "source": [
    "data_set = pd.read_csv(path+\"Small-diameter-flow.csv\") \n",
    "X = data_set.drop(columns=[\"Unnamed: 0\", \"Observer\", \"Flow\"])\n",
    "Y = data_set[[\"Flow\"]]\n",
    "flow = LinearRegression(X.values,list(X.columns),Y.values,Y.columns[0])\n",
    "#print( flow.con_int() )\n",
    "flow.print_all()\n",
    "#flow.SSR\n",
    "#import scipy.stats as st\n",
    "#scipy.stats.norm.ppf(0.975, 1, 0)\n",
    "#np.invNorm(0.975, 0, 1)\n",
    "\n",
    "#flow.con_int()\n",
    "#print( flow.confidence_intervals() )\n",
    "#flow.con_int()\n",
    "#flow.print_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LinearRegression.__init__() missing 2 required positional arguments: 'Y' and 'response'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[152], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m data_set\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m\"\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \n\u001b[0;32m      3\u001b[0m data_set\n\u001b[1;32m----> 4\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[43mLinearRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFlow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m obs\u001b[38;5;241m.\u001b[39mprint_all()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#print( obs.sig_var() )\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#print( obs.pearson() )\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#obs.con_int()\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#print( obs.confidence_level )\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#obs.SSR\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: LinearRegression.__init__() missing 2 required positional arguments: 'Y' and 'response'"
     ]
    }
   ],
   "source": [
    "data_set = pd.read_csv(path+\"Small-diameter-flow.csv\") \n",
    "data_set.drop(columns=[\"Unnamed: 0\"], inplace=True) \n",
    "data_set\n",
    "obs = LinearRegression(data_set, \"Flow\")\n",
    "\n",
    "obs.print_all()\n",
    "#print( obs.sig_var() )\n",
    "#print( obs.pearson() )\n",
    "#obs.con_int()\n",
    "#print( obs.confidence_level )\n",
    "#obs.SSR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.ipynb\n",
    "import pandas as pd\n",
    "path = \"../Resources/\" \n",
    "data_set = pd.read_csv(path+\"Advertising.csv\")\n",
    "data_set.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "adv = LinearRegression(data_set, \"sales\")\n",
    "\n",
    "# testa med e istället f\n",
    "#print(lr.con_int())\n",
    "#print(lr.con_int_2())\n",
    "#adv.print_all()\n",
    "#adv.b\n",
    "#adv.var()\n",
    "#adv.con_int()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Confidence intervals on individual parameters.\\n# confidence_level = 0.95\\n\\nS = np.sqrt{var} \\na = 0.05\\ndf = n-d-1\\n\\nc = np.linalg.pinv( (X.T @ X) ) * var\\n\\nstats.t.ppf(a/2, df) * S * np.sqrt(c[i][i])\\n\\n# β_i ± t_α/2 * σ * 2√cii\\n'"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Confidence intervals on individual parameters.\n",
    "# confidence_level = 0.95\n",
    "\n",
    "S = np.sqrt{var} \n",
    "a = 0.05\n",
    "df = n-d-1\n",
    "\n",
    "c = np.linalg.pinv( (X.T @ X) ) * var\n",
    "\n",
    "stats.t.ppf(a/2, df) * S * np.sqrt(c[i][i])\n",
    "\n",
    "# β_i ± t_α/2 * σ * 2√cii\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
# Edit Test
